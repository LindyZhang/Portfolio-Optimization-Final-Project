{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Final objective value                : 1.528801e-02\n",
      "            Final optimality                     : 2.900039e-07\n",
      "            Final feasibility                    : 1.443290e-15\n",
      "            Number of major iterations           : 16\n",
      "            Number of function evaluations       : 16\n",
      "            Number of derivative evaluations     : 16\n",
      "            Average Function evaluation time     : 0.000016 s per evaluation\n",
      "            Average Derivative evaluation time   : 0.000363 s per evaluation\n",
      "            Total Function evaluation time       : 0.000257 s [  0.16%]\n",
      "            Total Derivative evaluation time     : 0.005804 s [  3.72%]\n",
      "            Optimizer time                       : 0.035248 s [ 22.61%]\n",
      "            Processing time                      : 0.114556 s [ 73.50%]\n",
      "            Visualization time                   : 0.000000 s [  0.00%]\n",
      "            Total optimization time              : 0.155864 s [100.00%]\n",
      "            Summary saved to                     : slsqp_summary.out\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Final objective value                : 1.528965e-02\n",
      "            Final optimality                     : 7.876521e-07\n",
      "            Final feasibility                    : 0.000000e+00\n",
      "            Number of major iterations           : 14\n",
      "            Number of function evaluations       : 14\n",
      "            Number of derivative evaluations     : 14\n",
      "            Average Function evaluation time     : 0.000033 s per evaluation\n",
      "            Average Derivative evaluation time   : 0.000464 s per evaluation\n",
      "            Total Function evaluation time       : 0.000461 s [  0.44%]\n",
      "            Total Derivative evaluation time     : 0.006493 s [  6.18%]\n",
      "            Optimizer time                       : 0.008814 s [  8.39%]\n",
      "            Processing time                      : 0.089309 s [ 84.99%]\n",
      "            Visualization time                   : 0.000000 s [  0.00%]\n",
      "            Total optimization time              : 0.105077 s [100.00%]\n",
      "            Summary saved to                     : slsqp_summary.out\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Final objective value                : 3.221423e-02\n",
      "            Final optimality                     : 6.824547e-07\n",
      "            Final feasibility                    : 5.076495e-13\n",
      "            Number of major iterations           : 15\n",
      "            Number of function evaluations       : 15\n",
      "            Number of derivative evaluations     : 15\n",
      "            Average Function evaluation time     : 0.000057 s per evaluation\n",
      "            Average Derivative evaluation time   : 0.000573 s per evaluation\n",
      "            Total Function evaluation time       : 0.000858 s [  0.51%]\n",
      "            Total Derivative evaluation time     : 0.008600 s [  5.10%]\n",
      "            Optimizer time                       : 0.115302 s [ 68.32%]\n",
      "            Processing time                      : 0.044000 s [ 26.07%]\n",
      "            Visualization time                   : 0.000000 s [  0.00%]\n",
      "            Total optimization time              : 0.168760 s [100.00%]\n",
      "            Summary saved to                     : slsqp_summary.out\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Final objective value                : 1.438150e-02\n",
      "            Final optimality                     : 0.000000e+00\n",
      "            Final feasibility                    : 6.661338e-16\n",
      "            Number of major iterations           : 21\n",
      "            Number of function evaluations       : 21\n",
      "            Number of derivative evaluations     : 20\n",
      "            Average Function evaluation time     : 0.000012 s per evaluation\n",
      "            Average Derivative evaluation time   : 0.000167 s per evaluation\n",
      "            Total Function evaluation time       : 0.000262 s [  0.25%]\n",
      "            Total Derivative evaluation time     : 0.003331 s [  3.24%]\n",
      "            Optimizer time                       : 0.004410 s [  4.29%]\n",
      "            Processing time                      : 0.094846 s [ 92.22%]\n",
      "            Visualization time                   : 0.000000 s [  0.00%]\n",
      "            Total optimization time              : 0.102848 s [100.00%]\n",
      "            Summary saved to                     : slsqp_summary.out\n",
      "\n",
      "--- Clustered MVP ---\n",
      "\n",
      "Portfolio Weights:\n",
      "Clustered MVP: [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.22528976e-17\n",
      " 0.00000000e+00 5.82862674e-18 2.85258815e-17 5.93607655e-18\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 4.40144753e-17 0.00000000e+00 7.77262595e-18\n",
      " 1.71978863e-17 7.78089665e-20 1.87187638e-18 0.00000000e+00\n",
      " 1.23890985e-17 8.02687993e-18 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.34892027e-17\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.65839262e-17\n",
      " 9.62328927e-18 1.63851603e-17 0.00000000e+00 0.00000000e+00\n",
      " 1.93427062e-17 4.82269621e-05 8.08880612e-03 1.74484878e-02\n",
      " 1.82604441e-02 2.16288471e-02 3.37702293e-02 4.41479518e-02\n",
      " 9.93952499e-02 1.33520111e-01 1.36234223e-01 1.58121353e-01\n",
      " 1.65081266e-01 1.64254803e-01]\n",
      "Control: [0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02]\n",
      "\n",
      "Returns:\n",
      "Clustered MVP Return: 0.11167200711602746\n",
      "Control Return: 0.06135762340877478\n",
      "\n",
      "Variances:\n",
      "Clustered MVP Variance: 0.018442739521468896\n",
      "Control Variance: 0.057971049740761664\n",
      "\n",
      "Sharpe Ratios:\n",
      "Clustered MVP Sharpe: 0.5930931959058487\n",
      "Control Sharpe: 0.1255548859018428\n",
      "\n",
      "--- Full MVP ---\n",
      "MVP Weights: [6.21749378e-18 1.11671992e-17 9.52800632e-18 0.00000000e+00\n",
      " 4.75318786e-17 0.00000000e+00 0.00000000e+00 5.22322697e-17\n",
      " 0.00000000e+00 0.00000000e+00 8.55045358e-18 3.06031069e-17\n",
      " 4.66279241e-17 4.07005247e-17 2.11305540e-17 3.53424562e-18\n",
      " 0.00000000e+00 3.28997016e-17 0.00000000e+00 6.80267386e-02\n",
      " 1.47678714e-04 3.15780039e-03 1.17184353e-17 2.04840605e-01\n",
      " 3.42118519e-17 8.38817344e-18 1.55961056e-02 6.11360426e-18\n",
      " 2.74056587e-17 6.52114823e-04 2.55828532e-18 4.77179667e-02\n",
      " 5.57480550e-18 1.84164769e-17 1.34367608e-17 4.54750550e-17\n",
      " 1.69656816e-17 4.24587212e-17 2.88157618e-02 1.22899391e-01\n",
      " 4.97313125e-19 1.18489874e-01 9.21143634e-18 2.45599942e-18\n",
      " 1.45527686e-01 1.38062587e-01 0.00000000e+00 1.06065691e-01\n",
      " 0.00000000e+00 1.38743373e-17]\n",
      "Control Weights: [0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02]\n",
      "MVP Sharpe: 0.6743225477202779\n",
      "Control Sharpe: 0.37179327481429403\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from scipy.optimize import minimize\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "stocks_df = pd.read_csv('./sp500_stocks.csv')\n",
    "tickers = stocks_df['Symbol'].unique()\n",
    "\n",
    "#process prices into pivot table \n",
    "price_df = stocks_df.pivot(index='Date', columns='Symbol', values='Close')\n",
    "price_df = price_df.dropna(axis=1)  # remove stocks with missing prices\n",
    "tickers = price_df.columns.tolist()\n",
    "\n",
    "#compute Daily Returns\n",
    "returns_df = price_df.pct_change().dropna()\n",
    "\n",
    "def compute_distance_matrix(returns):\n",
    "    \"\"\"\n",
    "    computes a distance matrix based on correlation between asset returns\n",
    "\n",
    "    Parameters:\n",
    "    - returns (DataFrame): Return data.\n",
    "\n",
    "    Returns:\n",
    "    - (ndarray): Distance matrix where distance = 1 - correlation.\n",
    "    \"\"\"\n",
    "    corr = returns.corr().to_numpy()\n",
    "    dist = 1 - corr\n",
    "    return dist\n",
    "\n",
    "def agglomerative_clustering(distance_matrix, num_clusters):\n",
    "    \"\"\"\n",
    "    performs basic agglomerative hierarchical clustering using average linkage\n",
    "\n",
    "    Parameters:\n",
    "    - distance_matrix (ndarray): Distance between stocks\n",
    "    - num_clusters (int): Desired number of clusters\n",
    "\n",
    "    Returns:\n",
    "    - (list of lists): Each inner list contains indices of stocks in one cluster\n",
    "    \"\"\"\n",
    "    n = distance_matrix.shape[0]\n",
    "    clusters = [[i] for i in range(n)]\n",
    "    while len(clusters) > num_clusters:\n",
    "        min_dist = float('inf')\n",
    "        to_merge = (0, 1)\n",
    "        for i in range(len(clusters)):\n",
    "            for j in range(i + 1, len(clusters)):\n",
    "                dist_ij = np.mean([\n",
    "                    distance_matrix[a][b]\n",
    "                    for a in clusters[i]\n",
    "                    for b in clusters[j]\n",
    "                ])\n",
    "                if dist_ij < min_dist:\n",
    "                    min_dist = dist_ij\n",
    "                    to_merge = (i, j)\n",
    "        i, j = to_merge\n",
    "        merged = clusters[i] + clusters[j]\n",
    "        clusters = [c for k, c in enumerate(clusters) if k not in (i, j)]\n",
    "        clusters.append(merged)\n",
    "    return clusters\n",
    "\n",
    "def select_representatives(clusters, returns_df, symbols):\n",
    "    \"\"\"\n",
    "    selects one representative stock from each cluster: the one most similar to others in cluster with \n",
    "    smallest average distance to all other stocks in cluster\n",
    "\n",
    "    Parameters:\n",
    "    - clusters (list of lists): Output from agglomerative_clustering.\n",
    "    - returns_df (DataFrame): Daily returns data.\n",
    "    - symbols (list): List of all stock symbols.\n",
    "\n",
    "    Returns:\n",
    "    - (list): Symbols representing each cluster.\n",
    "    \"\"\"\n",
    "    corr_matrix = returns_df.corr()\n",
    "    representatives = []\n",
    "    for cluster in clusters:\n",
    "        if len(cluster) == 1:\n",
    "            representatives.append(symbols[cluster[0]])\n",
    "            continue\n",
    "        min_avg_dist = float('inf')\n",
    "        rep = cluster[0]\n",
    "        for i in cluster:\n",
    "            distances = [1 - corr_matrix.iloc[i, j] for j in cluster if i != j]\n",
    "            if not distances:\n",
    "                continue\n",
    "            avg_dist = np.mean(distances)\n",
    "            if avg_dist < min_avg_dist:\n",
    "                min_avg_dist = avg_dist\n",
    "                rep = i\n",
    "        representatives.append(symbols[rep])\n",
    "\n",
    "    return representatives\n",
    "\n",
    "#MVP functions\n",
    "def compute_returns(prices, time):\n",
    "    \"\"\"\n",
    "    computes log returns and expected returns over a specified time horizon.\n",
    "\n",
    "    Parameters:\n",
    "    - prices (DataFrame): Stock prices with dates as rows and symbols as columns.\n",
    "    - time (int): Number of trading days to scale the expected returns.\n",
    "\n",
    "    Returns:\n",
    "    - returns (DataFrame): Daily log returns for each stock.\n",
    "    - e_returns (Series): Expected returns scaled over the input time \n",
    "    \"\"\"\n",
    "    returns = np.log(prices / prices.shift(1)).dropna()\n",
    "    \n",
    "    daily_mean_returns = returns.mean()\n",
    "    e_returns = daily_mean_returns * time\n",
    "    \n",
    "    return returns, e_returns\n",
    "\n",
    "def build_estimate_covariance_matrix(returns, time):\n",
    "    \"\"\"\n",
    "    builds the estimated covariance matrix of asset returns, scaled over time\n",
    "\n",
    "    Parameters:\n",
    "    - returns (DataFrame): Daily returns for each asset.\n",
    "    - time (int): Scaling factor (number of trading days)\n",
    "\n",
    "    Returns:\n",
    "    - (ndarray): Covariance matrix (scaled by time)\n",
    "    \"\"\"\n",
    "    return returns.cov().to_numpy()*time\n",
    "\n",
    "def efficient_portfolio(mu, cov_matrix, mu_target):\n",
    "    \"\"\"\n",
    "    solves for the weights of an efficient portfolio given a return target\n",
    "\n",
    "    Parameters:\n",
    "    - mu (ndarray): Expected returns vector for each asset.\n",
    "    - cov_matrix (ndarray): Covariance matrix of asset returns.\n",
    "    - mu_target (float): Target expected return for the portfolio.\n",
    "\n",
    "    Returns:\n",
    "    - (ndarray): Optimal weights for the portfolio.\n",
    "    \"\"\"\n",
    "    n = len(mu)\n",
    "    mu = mu.reshape((n,))\n",
    "    ones = np.ones(n)\n",
    "\n",
    "    # Objective function: minimize portfolio variance\n",
    "    def fun(x):\n",
    "        return np.dot(x.T, np.dot(cov_matrix, x))\n",
    "    \n",
    "    # Gradient of the objective function\n",
    "    def jac(x):\n",
    "        return 2 * cov_matrix @ x\n",
    "\n",
    "    # Constraints\n",
    "    def c1(x):\n",
    "        return np.dot(mu, x) - mu_target\n",
    "\n",
    "    def c2(x):\n",
    "        return np.sum(x) - 1\n",
    "\n",
    "    def constraints(x):\n",
    "        return np.array([c1(x), c2(x)])\n",
    "\n",
    "    x0 = ones / n  # Initial guess\n",
    "\n",
    "    # Solve\n",
    "    result = pyslsqp.optimize(\n",
    "        x0, \n",
    "        obj=fun, \n",
    "        grad=jac, \n",
    "        con=constraints, \n",
    "        xl=0, xu=1 # Non-negativity of weights + weights cannot be > 1\n",
    "    )\n",
    "\n",
    "    return result['x']\n",
    "\n",
    "def run_experiment(prices, start_train, end_train, start_test, end_test):\n",
    "    \"\"\"\n",
    "    runs an MVP optimization experiment with a training and testing phase.\n",
    "\n",
    "    Parameters:\n",
    "    - prices (DataFrame): Price data for the assets.\n",
    "    - start_train, end_train (int): Training date indices.\n",
    "    - start_test, end_test (int): Testing date indices.\n",
    "\n",
    "    Returns:\n",
    "    - (dict): Portfolio performance metrics including weights, return, variance, and Sharpe ratio.\n",
    "    \"\"\"\n",
    "    num_stocks = prices.shape[1]\n",
    "    n = end_train - start_train\n",
    "    m = end_test - start_test\n",
    "\n",
    "    # increase to penalize risk more\n",
    "    risk_free_rate = np.log(1.04) * (m/252)  # r = log(1 + annual_rate)*(time/252)\n",
    "    \n",
    "    # returns and expected returns\n",
    "    ret, mu = compute_returns(prices.iloc[start_train:end_train], n)\n",
    "    ret_test, mu_test = compute_returns(prices.iloc[start_test:end_test], m)\n",
    "    \n",
    "    # estimate covariance matrix\n",
    "    estimate_covariance = build_estimate_covariance_matrix(ret, n)\n",
    "    covariance_test = build_estimate_covariance_matrix(ret_test, m)\n",
    "    \n",
    "    # portfolios\n",
    "    MVP = efficient_portfolio(mu.to_numpy(), estimate_covariance, 0.25)\n",
    "    Control = np.ones(num_stocks) / num_stocks\n",
    "    \n",
    "    MVP_return = np.dot(mu_test, MVP)\n",
    "    Control_return = np.dot(Control, mu_test)\n",
    "    \n",
    "    MVP_cov = np.dot(np.dot(MVP.T, covariance_test), MVP)\n",
    "    Control_cov = np.dot(np.dot(Control.T, covariance_test), Control)\n",
    "    \n",
    "\n",
    "    MVP_sharpe = (MVP_return - risk_free_rate) / math.sqrt(MVP_cov)\n",
    "    Control_sharpe = (Control_return - risk_free_rate) / math.sqrt(Control_cov)\n",
    "\n",
    "    metrics = {'MVP Weights': MVP,\n",
    "               'Control Weights': Control,\n",
    "               'MVP Return' : MVP_return, \n",
    "               'Control Return': Control_return,\n",
    "               'MVP Cov' : MVP_cov,\n",
    "               'Control Cov': Control_cov,\n",
    "               'MVP Sharpe': MVP_sharpe,\n",
    "               'Control Sharpe': Control_sharpe}\n",
    "    return metrics\n",
    "\n",
    "#select representative prices of clustered stocks and run experiment\n",
    "# main process: 100 clusters -> MVP -> select top 50 by weight -> rerun MVP\n",
    "distance_matrix = compute_distance_matrix(returns_df)\n",
    "clusters_100 = agglomerative_clustering(distance_matrix, num_clusters=100)\n",
    "reps_100 = select_representatives(clusters_100, returns_df, tickers)\n",
    "rep_prices_100 = price_df[reps_100].copy()\n",
    "\n",
    "intermediate_results = run_experiment(rep_prices_100, 0, 400, 400, 600)\n",
    "cluster_top_50_indices = np.argsort(intermediate_results['MVP Weights'])[-50:]\n",
    "cluster_top_50_tickers = [reps_100[i] for i in cluster_top_50_indices]\n",
    "cluster_top_50_prices = price_df[cluster_top_50_tickers]\n",
    "\n",
    "results = run_experiment(cluster_top_50_prices, 0, 400, 400, 600)\n",
    "\n",
    "results\n",
    "\n",
    "# compute returns and covariance for all 500 stocks for full MVP\n",
    "full_returns, full_mu = compute_returns(price_df, time=400)\n",
    "full_covariance = build_estimate_covariance_matrix(full_returns, time=400)\n",
    "\n",
    "# run MVP optimization on all 500 stocks using target return\n",
    "full_MVP_weights = efficient_portfolio(full_mu.to_numpy(), full_covariance, mu_target=0.25)\n",
    "\n",
    "# select top 50 stocks based on absolute MVP weights for full MVP\n",
    "top_50_indices = np.argsort(full_MVP_weights)[-50:]\n",
    "top_50_tickers = price_df.columns[top_50_indices]\n",
    "top_50_prices = price_df[top_50_tickers]\n",
    "\n",
    "results_full_MVP = run_experiment(top_50_prices, 0, 400, 400, 600)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) #to prevent log(0) warnings\n",
    "\n",
    "# results output\n",
    "print(\"\\n--- Clustered MVP ---\")\n",
    "print(\"\\nPortfolio Weights:\")\n",
    "print(\"Clustered MVP:\", results['MVP Weights'])\n",
    "print(\"Control:\", results['Control Weights'])\n",
    "\n",
    "print(\"\\nReturns:\")\n",
    "print(\"Clustered MVP Return:\", results['MVP Return'])\n",
    "print(\"Control Return:\", results['Control Return'])\n",
    "\n",
    "print(\"\\nVariances:\")\n",
    "print(\"Clustered MVP Variance:\", results['MVP Cov'])\n",
    "print(\"Control Variance:\", results['Control Cov'])\n",
    "\n",
    "print(\"\\nSharpe Ratios:\")\n",
    "print(\"Clustered MVP Sharpe:\", results['MVP Sharpe'])\n",
    "print(\"Control Sharpe:\", results['Control Sharpe'])\n",
    "\n",
    "print(\"\\n--- Full MVP ---\")\n",
    "print(\"MVP Weights:\", results_full_MVP['MVP Weights'])\n",
    "print(\"Control Weights:\", results_full_MVP['Control Weights'])\n",
    "print(\"MVP Sharpe:\", results_full_MVP['MVP Sharpe'])\n",
    "print(\"Control Sharpe:\", results_full_MVP['Control Sharpe'])\n",
    "\n",
    "# plot results\n",
    "cluster_top_50_prices.iloc[:90].plot(figsize=(10, 6))\n",
    "plt.title(\"Prices Over Time for Cluster Representatives\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5), fontsize='small', ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# prices for full MVP\n",
    "top_50_prices.iloc[:90].plot(figsize=(10, 6))\n",
    "plt.title(\"Prices Over Time for Full MVP (Top 50 Stocks)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5), fontsize='small', ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Return vs Variance Scatter\n",
    "x = [results['MVP Return'], results['Control Return'], results_full_MVP['MVP Return']]\n",
    "y = [results['MVP Cov'], results['Control Cov'], results_full_MVP['MVP Cov']]\n",
    "labels = [\"Clustered MVP\", \"Control\", \"Full MVP\"]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "for i, txt in enumerate(labels):\n",
    "    ax.annotate(txt, (x[i], y[i]))\n",
    "plt.xlabel(\"Rate of Return\")\n",
    "plt.ylabel(\"Covariance of Portfolio\")\n",
    "plt.title(\"Return vs Variance\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# plot sharpe ratios\n",
    "sharpe_ratios = [\n",
    "    results['MVP Sharpe'],\n",
    "    results['Control Sharpe'],\n",
    "    results_full_MVP['MVP Sharpe']\n",
    "]\n",
    "\n",
    "labels = ['Clustered MVP', 'Control', 'Full MVP']\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(labels, sharpe_ratios, color=colors)\n",
    "plt.ylabel('Sharpe Ratio')\n",
    "plt.title('Sharpe Ratios Comparison')\n",
    "for i, v in enumerate(sharpe_ratios):\n",
    "    plt.text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom')\n",
    "plt.ylim(0, max(sharpe_ratios)*1.2)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1807380,
     "sourceId": 10273516,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
